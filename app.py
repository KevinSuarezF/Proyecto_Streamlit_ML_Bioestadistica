import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')
import os
import time

# Bibliotecas de ML
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, RandomizedSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.decomposition import PCA
from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif, RFECV
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier,
                           HistGradientBoostingClassifier, ExtraTreesClassifier)
from sklearn.svm import SVC
from sklearn.metrics import (accuracy_score, precision_score, recall_score,
                           f1_score, roc_auc_score, confusion_matrix, ConfusionMatrixDisplay,
                           classification_report, roc_curve, auc, RocCurveDisplay)

# Balanceo de datos
from imblearn.over_sampling import SMOTE, ADASYN, BorderlineSMOTE, SVMSMOTE, RandomOverSampler
from imblearn.under_sampling import RandomUnderSampler, TomekLinks, EditedNearestNeighbours, NearMiss
from imblearn.combine import SMOTEENN, SMOTETomek

from scipy.stats import randint, uniform
from sklearn.utils import resample

# MCA
try:
    from mca import MCA
    MCA_AVAILABLE = True
except ImportError:
    MCA_AVAILABLE = False

# Configuraci√≥n de matplotlib para Streamlit
plt.style.use('default')
plt.rcParams['figure.figsize'] = (10, 6)

# Configuraci√≥n de la p√°gina
st.set_page_config(
    page_title="Trabajo Final ML Bioestad√≠stica",
    page_icon="üìä",
    layout="wide",
    initial_sidebar_state="expanded"
)

def main():
    st.title("An√°lisis Comparativo de T√©cnicas de Reducci√≥n de Dimensionalidad en Predicci√≥n de Estado de Salud: PCA, MCA y Selecci√≥n de Caracter√≠sticas")
    st.markdown("### Trabajo Final - Machine Learning en Bioestad√≠stica")
    st.markdown("**Autores:** David Zabala y Kevin Suarez | **Fecha:** Agosto 2025")
    
    # Inicializar estado de la sesi√≥n si no existe
    if 'analisis_completado' not in st.session_state:
        st.session_state.analisis_completado = False
        st.session_state.resultados_analisis = None
    
    # Sidebar para navegaci√≥n
    st.sidebar.title("Navegaci√≥n")
    
    # Bot√≥n principal para ejecutar el an√°lisis
    if st.sidebar.button("Ejecutar An√°lisis Completo", type="primary", use_container_width=True):
        st.session_state.analisis_completado = True
        st.session_state.resultados_analisis = ejecutar_analisis_completo()
        st.rerun()
    
    # Mostrar men√∫s seg√∫n el estado
    if not st.session_state.analisis_completado:
        # Men√∫ inicial - antes de ejecutar an√°lisis
        st.sidebar.markdown("---")
        st.sidebar.markdown("### Secciones del An√°lisis")
        
        seccion = st.sidebar.selectbox(
            "Seleccionar secci√≥n:",
            ["Resumen Ejecutivo", "Configuraci√≥n del Entorno", "An√°lisis Exploratorio", 
             "Preprocesamiento", "Selecci√≥n de Caracter√≠sticas", "PCA y MCA", 
             "T√©cnicas de Balanceo", "Modelos de Clasificaci√≥n", "Resultados", "Conclusiones"],
            index=0
        )
        
        if seccion == "Resumen Ejecutivo":
            mostrar_resumen_ejecutivo()
        elif seccion == "Configuraci√≥n del Entorno":
            mostrar_configuracion()
        elif seccion == "An√°lisis Exploratorio":
            mostrar_analisis_exploratorio()
        elif seccion == "Preprocesamiento":
            mostrar_preprocesamiento()
        elif seccion == "Selecci√≥n de Caracter√≠sticas":
            mostrar_seleccion_caracteristicas()
        elif seccion == "PCA y MCA":
            mostrar_pca_mca()
        elif seccion == "T√©cnicas de Balanceo":
            mostrar_balanceo()
        elif seccion == "Modelos de Clasificaci√≥n":
            mostrar_modelos()
        elif seccion == "Resultados":
            mostrar_resultados()
        elif seccion == "Conclusiones":
            mostrar_conclusiones()
    else:
        # Men√∫ despu√©s del an√°lisis - mostrar resultados
        st.sidebar.markdown("---")
        st.sidebar.markdown("### An√°lisis Completado")
        
        # Bot√≥n para reiniciar an√°lisis
        if st.sidebar.button("Ejecutar Nuevo An√°lisis", use_container_width=True):
            st.session_state.analisis_completado = True
            st.session_state.resultados_analisis = ejecutar_analisis_completo()
            st.rerun()
        
        if st.sidebar.button("Volver al Men√∫ Principal", use_container_width=True):
            st.session_state.analisis_completado = False
            st.session_state.resultados_analisis = None
            st.rerun()
        
        st.sidebar.markdown("---")
        st.sidebar.markdown("### Resultados del An√°lisis")
        
        seccion_resultados = st.sidebar.selectbox(
            "Ver resultados de:",
            ["Resumen Completo", "Carga de Datos", "An√°lisis Exploratorio",
             "Preprocesamiento", "Selecci√≥n de Caracter√≠sticas", "PCA y MCA",
             "T√©cnicas de Balanceo", "Modelos Entrenados", "Mejores Resultados",
             "Comparaci√≥n de Modelos", "Conclusiones Finales"],
            index=0
        )
        
        # Mostrar la secci√≥n seleccionada de resultados
        if st.session_state.resultados_analisis:
            mostrar_seccion_resultados(seccion_resultados, st.session_state.resultados_analisis)
        else:
            st.error("No hay resultados disponibles. Por favor, ejecuta el an√°lisis primero.")

def mostrar_resumen_ejecutivo():
    st.header("Resumen Ejecutivo")
    
    st.markdown("""
    Este trabajo presenta un an√°lisis exhaustivo de t√©cnicas de reducci√≥n de dimensionalidad 
    aplicadas a la predicci√≥n del estado de salud usando datos de estilo de vida. Se comparan 
    metodol√≥gicamente tres enfoques principales: **An√°lisis de Componentes Principales (PCA)**, 
    **An√°lisis de Correspondencias M√∫ltiples (MCA)** y **t√©cnicas de selecci√≥n de caracter√≠sticas**, 
    evaluando su impacto en el rendimiento predictivo y la interpretabilidad cl√≠nica.
    """)
    
    st.subheader("OBJETIVOS")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("""
        #### **Objetivo General:**
        Evaluar y comparar la efectividad de diferentes t√©cnicas de reducci√≥n de dimensionalidad 
        para la predicci√≥n del estado de salud en un contexto bioestad√≠stico, priorizando tanto 
        el rendimiento predictivo como la interpretabilidad m√©dica.
        """)
    
    with col2:
        st.markdown("""
        #### **Objetivos Espec√≠ficos:**
        1. **Implementar y comparar** t√©cnicas de selecci√≥n de caracter√≠sticas
        2. **Aplicar PCA** a variables num√©ricas para reducci√≥n dimensional
        3. **Implementar MCA** en variables categ√≥ricas 
        4. **Evaluar el impacto** de t√©cnicas de balanceo
        5. **Comparar m√∫ltiples algoritmos** de clasificaci√≥n
        6. **Proporcionar recomendaciones** para aplicaciones cl√≠nicas
        """)
    
    st.subheader("DATASET")
    st.info("""
    **Health Lifestyle Dataset** - Datos de estilo de vida y salud de 100,000 personas:
    - **Muestra analizada:** 50,000 registros seleccionados aleatoriamente de forma estratificada
    - **Variables num√©ricas:** age, bmi, blood_pressure, cholesterol, glucose, sleep_hours, etc.
    - **Variables categ√≥ricas:** gender, marital_status, diet_type, occupation, healthcare_access, etc.
    - **Variable objetivo:** Clasificaci√≥n binaria (healthy/diseased)
    - **Desbalance de clases:** ~70% sanos vs ~30% enfermos
    """)
    
    st.subheader("METODOLOG√çA")
    metodologia_pasos = [
        "An√°lisis Exploratorio Exhaustivo con visualizaciones interpretativas",
        "Preprocesamiento Robusto con pipelines y validaci√≥n anti-leakage", 
        "Comparaci√≥n de 4 T√©cnicas de Selecci√≥n: Chi¬≤, Informaci√≥n Mutua, Random Forest, RFECV",
        "Implementaci√≥n de PCA y MCA con criterios de varianza explicada",
        "Evaluaci√≥n de 8 T√©cnicas de Balanceo para manejo de clases desbalanceadas",
        "Optimizaci√≥n de 5 Algoritmos con RandomizedSearchCV y validaci√≥n cruzada",
        "An√°lisis Comparativo Integral con m√©tricas m√∫ltiples y curvas ROC"
    ]
    
    for i, paso in enumerate(metodologia_pasos, 1):
        st.markdown(f"{i}. {paso}")

def mostrar_configuracion():
    st.header("Configuraci√≥n del Entorno y Librer√≠as")

    st.markdown("""
    Importamos todas las librer√≠as necesarias para el an√°lisis, organizadas por funcionalidad 
    para facilitar la reproducibilidad y mantenimiento del c√≥digo.
    """)
    
    st.subheader("Librer√≠as Principales")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.code("""
# Bibliotecas principales
import pandas as pd
import numpy as np
import warnings
warnings.filterwarnings('ignore')

# Visualizaci√≥n
import matplotlib.pyplot as plt
import seaborn as sns
        """, language="python")
        
    with col2:
        st.code("""
# Preprocessing y divisi√≥n de datos
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
        """, language="python")
    
    st.subheader("Librer√≠as de Machine Learning")
    
    with st.expander("Ver todas las importaciones"):
        st.code("""
# Reducci√≥n de dimensionalidad
from sklearn.decomposition import PCA
import mca  # Para MCA
from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif, RFECV

# Modelos de clasificaci√≥n
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC

# M√©tricas de evaluaci√≥n
from sklearn.metrics import accuracy_score, precision_score, recall_score
from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix

# Balanceo de datos
from imblearn.over_sampling import SMOTE, BorderlineSMOTE
from imblearn.combine import SMOTEENN, SMOTETomek
        """, language="python")

def ejecutar_analisis_completo():
    """Ejecuta todo el pipeline de an√°lisis paso a paso"""
    st.header("üîÑ Ejecutando An√°lisis Completo")
    
    # Crear contenedores para actualizar el progreso
    progress_container = st.container()
    status_container = st.container()
    results_container = st.container()
    
    with progress_container:
        progress_bar = st.progress(0)
        status_text = st.empty()
    
    # Lista de pasos del an√°lisis
    pasos = [
        ("Cargando y preparando datos...", cargar_datos),
        ("Realizando an√°lisis exploratorio...", lambda df: analisis_exploratorio(df)),
        ("Preprocesando datos...", lambda df: preprocesar_datos(df)),
        ("Aplicando selecci√≥n de caracter√≠sticas...", lambda data: seleccion_caracteristicas(data)),
        ("Ejecutando PCA y MCA...", lambda data: aplicar_pca_mca(data)),
        ("Aplicando t√©cnicas de balanceo...", lambda data: aplicar_balanceo(data)),
        ("Entrenando modelos de clasificaci√≥n...", lambda data: entrenar_modelos(data)),
        ("Generando resultados finales...", lambda data: generar_resultados(data)),
        ("¬°An√°lisis completado!", lambda data: None)
    ]
    
    # Estado compartido para pasar datos entre pasos
    analisis_estado = {}
    
    for i, (descripcion, funcion) in enumerate(pasos):
        with status_container:
            status_text.text(descripcion)
        
        progress_bar.progress((i + 1) / len(pasos))
        
        # Ejecutar funci√≥n si no es el √∫ltimo paso
        if funcion is not None:
            try:
                if i == 0:  # Cargar datos
                    resultado = funcion()
                else:  # Otros pasos
                    resultado = funcion(analisis_estado)
                
                if resultado is not None:
                    analisis_estado.update(resultado)
                    
                time.sleep(1)  # Pausa para mostrar el progreso
                
            except Exception as e:
                st.error(f"Error en el paso {i+1}: {str(e)}")
                return None
    
    with results_container:
        st.success("‚úÖ An√°lisis completado exitosamente!")
        
        # Mostrar resumen de resultados si est√°n disponibles
        if 'resultados_finales' in analisis_estado:
            mostrar_resultados_completos(analisis_estado['resultados_finales'])
    
    return analisis_estado

def cargar_datos():
    """Carga y prepara el dataset"""
    st.subheader("üìÇ Carga de Datos")
    
    try:
        # Intentar cargar datos originales usando kagglehub
        st.info("üí° Descargando Health Lifestyle Dataset desde Kaggle...")
        
        with st.spinner("Descargando datos..."):
            import kagglehub
            path = kagglehub.dataset_download("mahdimashayekhi/disease-risk-from-daily-habits")
            csv_files = [f for f in os.listdir(path) if f.endswith('.csv')]
            csv_path = os.path.join(path, csv_files[0])
            df_original = pd.read_csv(csv_path)
            
            # Muestreo estratificado de 50,000 registros (como en el notebook)
            df, _, _, _ = train_test_split(
                df_original, 
                df_original['target'], 
                train_size=0.5,  # 50% de 100,000 = 50,000
                stratify=df_original['target'], 
                random_state=123
            )
            
            # Eliminar columnas como en el notebook
            columns_to_drop = ['survey_code', 'electrolyte_level']
            df = df.drop(columns=[col for col in columns_to_drop if col in df.columns])
            
        st.success("‚úÖ Datos originales cargados desde Kaggle")
        
    except Exception as e:
        st.warning(f"No se pudieron cargar los datos originales: {str(e)}")
        st.info("Usando datos sint√©ticos para demostraci√≥n...")
        
        # Fallback a datos sint√©ticos (c√≥digo actual)
        np.random.seed(123)
        n_samples = 5000  # Muestra m√°s peque√±a para la demo
        
        # Generar datos sint√©ticos similares al dataset original
        data = {
            'age': np.random.normal(45, 15, n_samples).clip(18, 80),
            'bmi_corrected': np.random.normal(25, 5, n_samples).clip(15, 50),
            'blood_pressure': np.random.normal(120, 20, n_samples).clip(80, 200),
            'cholesterol': np.random.normal(200, 40, n_samples).clip(100, 400),
            'glucose': np.random.normal(100, 20, n_samples).clip(70, 200),
            'sleep_hours': np.random.normal(7, 1.5, n_samples).clip(4, 12),
            'weight': np.random.normal(70, 15, n_samples).clip(40, 120),
            'height': np.random.normal(170, 10, n_samples).clip(150, 200),
            'gender': np.random.choice(['Male', 'Female'], n_samples),
            'marital_status': np.random.choice(['Single', 'Married', 'Divorced'], n_samples),
            'sleep_quality': np.random.choice(['Poor', 'Fair', 'Good', 'Excellent'], n_samples),
            'smoking_level': np.random.choice(['None', 'Light', 'Moderate', 'Heavy'], n_samples),
            'diet_type': np.random.choice(['Balanced', 'Vegetarian', 'Keto', 'Mediterranean'], n_samples),
            'healthcare_access': np.random.choice(['Limited', 'Adequate', 'Excellent'], n_samples),
            'occupation': np.random.choice(['Office', 'Manual', 'Healthcare', 'Education'], n_samples)
        }
        
        df = pd.DataFrame(data)
        
        # Crear variable objetivo con cierta l√≥gica (no completamente aleatoria)
        # Factores que aumentan probabilidad de enfermedad
        prob_disease = 0.3  # Probabilidad base
        
        # Ajustar probabilidad basada en factores de riesgo
        risk_factors = (
            (df['age'] > 60) * 0.2 +
            (df['bmi_corrected'] > 30) * 0.2 +  
            (df['blood_pressure'] > 140) * 0.2 +
            (df['smoking_level'].isin(['Moderate', 'Heavy'])) * 0.2 +
            (df['sleep_hours'] < 6) * 0.1
        )
        
        final_prob = prob_disease + risk_factors
        df['target'] = np.random.binomial(1, final_prob.clip(0, 1), n_samples)
        df['target'] = df['target'].map({0: 'healthy', 1: 'diseased'})
    
    # Mostrar informaci√≥n b√°sica
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Total de registros", f"{len(df):,}")
    with col2:
        st.metric("Variables num√©ricas", len(df.select_dtypes(include=[np.number]).columns) - 1)
    with col3:
        st.metric("Variables categ√≥ricas", len(df.select_dtypes(include=['object']).columns) - 1)
    
    st.write("**Vista previa de los datos:**")
    st.dataframe(df.head())
    
    return {'df': df, 'mensaje': 'Datos cargados correctamente'}

def analisis_exploratorio(estado):
    """Realiza el an√°lisis exploratorio de datos"""
    st.subheader("An√°lisis Exploratorio de Datos")
    
    df = estado['df']
    
    # Separar variables por tipo
    numerical_cols = df.select_dtypes(include=[np.number]).columns.tolist()
    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
    
    if 'target' in numerical_cols:
        numerical_cols.remove('target')
    if 'target' in categorical_cols:
        categorical_cols.remove('target')
    
    # Distribuci√≥n de la variable objetivo
    st.write("### Distribuci√≥n de la Variable Objetivo")
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        fig, ax = plt.subplots(figsize=(8, 5))
        target_counts = df['target'].value_counts()
        target_props = df['target'].value_counts(normalize=True)
        
        bars = ax.bar(target_counts.index, target_counts.values, color=['#1f77b4', '#ff7f0e'])
        ax.set_title('Distribuci√≥n de la Variable Objetivo', fontsize=14, fontweight='bold')
        ax.set_xlabel('Estado de Salud')
        ax.set_ylabel('N√∫mero de Personas')
        
        # Agregar porcentajes sobre barras
        for bar, prop in zip(bars, target_props):
            height = bar.get_height()
            ax.annotate(f'{prop:.1%}', 
                       (bar.get_x() + bar.get_width()/2, height),
                       ha='center', va='bottom', fontsize=12, color='black')
        
        st.pyplot(fig)
    
    with col2:
        st.write("**Distribuci√≥n:**")
        for val in target_counts.index:
            st.metric(val.title(), f"{target_counts[val]:,}", f"{target_props[val]:.1%}")
    
    # Distribuci√≥n de variables num√©ricas
    st.write("### Distribuci√≥n de Variables Num√©ricas Clave")
    
    variables_importantes = ['age', 'bmi_corrected', 'blood_pressure', 'cholesterol', 'glucose', 'sleep_hours']
    variables_disponibles = [var for var in variables_importantes if var in numerical_cols]
    
    if variables_disponibles:
        fig, axes = plt.subplots(2, 3, figsize=(15, 10))
        axes = axes.flatten()
        
        for i, var in enumerate(variables_disponibles[:6]):
            if i < len(axes):
                axes[i].hist(df[var], bins=30, alpha=0.7, color='skyblue', edgecolor='black')
                axes[i].set_title(f'Distribuci√≥n de {var}', fontweight='bold')
                axes[i].set_xlabel(var)
                axes[i].set_ylabel('Frecuencia')
                axes[i].grid(True, alpha=0.3)
        
        # Ocultar subplots vac√≠os
        for j in range(len(variables_disponibles), len(axes)):
            axes[j].set_visible(False)
        
        plt.tight_layout()
        st.pyplot(fig)
    
    # Matriz de correlaci√≥n
    st.write("### Matriz de Correlaci√≥n de Variables Num√©ricas")
    
    if len(numerical_cols) > 1:
        fig, ax = plt.subplots(figsize=(10, 8))
        correlation_matrix = df[numerical_cols].corr()
        
        sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,
                   square=True, ax=ax, fmt='.2f')
        ax.set_title('Matriz de Correlaci√≥n de Variables Num√©ricas', fontweight='bold')
        plt.tight_layout()
        st.pyplot(fig)
    
    # Variables categ√≥ricas vs target
    st.write("### Variables Categ√≥ricas vs Variable Objetivo")
    
    variables_cat_importantes = ['gender', 'sleep_quality', 'smoking_level', 'diet_type']
    variables_cat_disponibles = [var for var in variables_cat_importantes if var in categorical_cols]
    
    if variables_cat_disponibles:
        n_vars = len(variables_cat_disponibles)
        cols_per_row = min(2, n_vars)
        n_rows = (n_vars + cols_per_row - 1) // cols_per_row
        
        fig, axes = plt.subplots(n_rows, cols_per_row, figsize=(15, 5 * n_rows))
        if n_rows == 1:
            axes = [axes] if n_vars == 1 else axes
        else:
            axes = axes.flatten()
        
        for i, var in enumerate(variables_cat_disponibles):
            if df[var].nunique() < 10:  # Solo mostrar si no hay demasiadas categor√≠as
                cross_tab = pd.crosstab(df[var], df['target'], normalize='index') * 100
                
                ax = axes[i] if n_vars > 1 else axes
                cross_tab.plot(kind='bar', ax=ax, color=['#1f77b4', '#ff7f0e'])
                ax.set_title(f'Distribuci√≥n de {var} por Estado de Salud (%)', fontweight='bold')
                ax.set_xlabel(var)
                ax.set_ylabel('Porcentaje')
                ax.legend(title='Estado')
                ax.tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        st.pyplot(fig)
    
    return {
        'numerical_cols': numerical_cols,
        'categorical_cols': categorical_cols,
        'mensaje': 'An√°lisis exploratorio completado'
    }

def preprocesar_datos(estado):
    """Preprocesa los datos dividi√©ndolos en train/test y aplicando pipelines"""
    st.subheader("Preprocesamiento de Datos")
    
    df = estado['df']
    numerical_cols = estado['numerical_cols']
    categorical_cols = estado['categorical_cols']
    
    # Separar X e y
    X = df.drop('target', axis=1)
    y = df['target']
    
    # Divisi√≥n estratificada
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=123, stratify=y
    )
    
    # Pipelines de preprocesamiento
    num_pipeline = Pipeline([
        ('imputer', SimpleImputer(strategy='mean')),
        ('scaler', StandardScaler())
    ])
    
    cat_pipeline = Pipeline([
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('encoder', OneHotEncoder(handle_unknown='ignore'))
    ])
    
    preprocessor = ColumnTransformer([
        ('num', num_pipeline, numerical_cols),
        ('cat', cat_pipeline, categorical_cols)
    ])
    
    # Aplicar preprocesamiento
    X_train_processed = preprocessor.fit_transform(X_train)
    X_test_processed = preprocessor.transform(X_test)
    
    # Codificar variable objetivo
    le = LabelEncoder()
    y_train_enc = le.fit_transform(y_train)
    y_test_enc = le.transform(y_test)
    
    col1, col2 = st.columns(2)
    with col1:
        st.metric("Datos de entrenamiento", f"{X_train_processed.shape[0]:,} √ó {X_train_processed.shape[1]}")
    with col2:
        st.metric("Datos de prueba", f"{X_test_processed.shape[0]:,} √ó {X_test_processed.shape[1]}")
    
    st.success("‚úÖ Preprocesamiento completado")
    
    return {
        'X_train': X_train,
        'X_test': X_test,
        'y_train': y_train,
        'y_test': y_test,
        'X_train_processed': X_train_processed,
        'X_test_processed': X_test_processed,
        'y_train_enc': y_train_enc,
        'y_test_enc': y_test_enc,
        'preprocessor': preprocessor,
        'le': le,
        'mensaje': 'Datos preprocesados correctamente'
    }

def seleccion_caracteristicas(estado):
    """Aplica diferentes t√©cnicas de selecci√≥n de caracter√≠sticas"""
    st.subheader("Selecci√≥n de Caracter√≠sticas")
    
    X_train_processed = estado['X_train_processed']
    X_test_processed = estado['X_test_processed']
    y_train_enc = estado['y_train_enc']
    preprocessor = estado['preprocessor']
    
    # Obtener nombres de caracter√≠sticas
    feature_names = preprocessor.get_feature_names_out()
    
    st.write("### Random Forest - M√©todo Incrustado")
    
    # Random Forest para importancia de caracter√≠sticas
    rf_model = RandomForestClassifier(n_estimators=100, random_state=123)
    rf_model.fit(X_train_processed, y_train_enc)
    
    importances = rf_model.feature_importances_
    indices = np.argsort(importances)[::-1]
    
    # Calcular caracter√≠sticas necesarias para 90% de importancia
    sorted_importances = importances[indices]
    cumulative_importance = np.cumsum(sorted_importances)
    n_features_90 = np.searchsorted(cumulative_importance, 0.9) + 1
    
    # Visualizar importancia
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # Top 10 caracter√≠sticas m√°s importantes
    top_n = min(10, len(feature_names))
    ax1.bar(range(top_n), sorted_importances[:top_n])
    ax1.set_title('Top 10 Caracter√≠sticas (Random Forest)', fontweight='bold')
    ax1.set_xlabel('Caracter√≠sticas')
    ax1.set_ylabel('Importancia')
    ax1.tick_params(axis='x', rotation=45)
    
    # Importancia acumulada
    ax2.plot(range(1, len(cumulative_importance) + 1), cumulative_importance, 'o-')
    ax2.axhline(y=0.9, color='r', linestyle='--', label='90% Umbral')
    ax2.axvline(x=n_features_90, color='r', linestyle='--', alpha=0.7)
    ax2.set_xlabel('N√∫mero de Caracter√≠sticas')
    ax2.set_ylabel('Importancia Acumulada')
    ax2.set_title('Importancia Acumulada', fontweight='bold')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    st.pyplot(fig)
    
    # Seleccionar caracter√≠sticas m√°s importantes
    selected_indices = indices[:n_features_90]
    X_train_selected = X_train_processed[:, selected_indices]
    X_test_selected = X_test_processed[:, selected_indices] 
    
    st.info(f"üí° Seleccionadas {n_features_90} caracter√≠sticas que explican el 90% de la importancia")
    
    return {
        'X_train_selected': X_train_selected,
        'X_test_selected': X_test_selected,
        'selected_features': feature_names[selected_indices],
        'n_features_selected': n_features_90,
        'mensaje': f'Seleccionadas {n_features_90} caracter√≠sticas importantes'
    }

def aplicar_pca_mca(estado):
    """Aplica PCA a variables num√©ricas y MCA a categ√≥ricas"""
    st.subheader("PCA y MCA")
    
    X_train = estado['X_train'] 
    X_test = estado['X_test']
    numerical_cols = estado['numerical_cols']
    categorical_cols = estado['categorical_cols']
    y_train = estado['y_train']
    
    st.write("### An√°lisis de Componentes Principales (PCA)")
    
    # Pipeline para variables num√©ricas
    num_pipeline_pca = Pipeline([
        ('imputer', SimpleImputer(strategy='mean')),
        ('scaler', StandardScaler())
    ])
    
    X_train_num = num_pipeline_pca.fit_transform(X_train[numerical_cols])
    X_test_num = num_pipeline_pca.transform(X_test[numerical_cols])
    
    # Aplicar PCA
    pca = PCA(n_components=0.7, random_state=123)
    X_train_pca = pca.fit_transform(X_train_num)
    X_test_pca = pca.transform(X_test_num)
    
    # Visualizar varianza explicada
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # Varianza explicada por componente
    ax1.bar(range(1, len(pca.explained_variance_ratio_) + 1), pca.explained_variance_ratio_)
    ax1.set_title('Varianza Explicada por Componente PCA', fontweight='bold')
    ax1.set_xlabel('Componente Principal')
    ax1.set_ylabel('Proporci√≥n de Varianza Explicada')
    
    # Varianza acumulada
    cumvar = np.cumsum(pca.explained_variance_ratio_)
    ax2.plot(range(1, len(cumvar) + 1), cumvar, 'o-')
    ax2.axhline(y=0.7, color='r', linestyle='--', label='70% Umbral')
    ax2.set_title('Varianza Acumulada PCA', fontweight='bold')
    ax2.set_xlabel('N√∫mero de Componentes')
    ax2.set_ylabel('Varianza Acumulada')
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    st.pyplot(fig)
    
    # Scatter plot PC1 vs PC2
    if X_train_pca.shape[1] >= 2:
        fig, ax = plt.subplots(figsize=(10, 8))
        scatter = ax.scatter(X_train_pca[:, 0], X_train_pca[:, 1], 
                           c=[0 if target == 'healthy' else 1 for target in y_train],
                           cmap='viridis', alpha=0.6)
        ax.set_xlabel('PC1')
        ax.set_ylabel('PC2') 
        ax.set_title('Scatter Plot PC1 vs PC2', fontweight='bold')
        plt.colorbar(scatter, label='Target (0=healthy, 1=diseased)')
        st.pyplot(fig)
    
    st.info(f"PCA: {X_train_pca.shape[1]} componentes explican {cumvar[-1]:.1%} de la varianza")
    
    # MCA - An√°lisis de Correspondencias M√∫ltiples (siguiendo el notebook)
    st.write("### An√°lisis de Correspondencias M√∫ltiples (MCA)")
    
    if MCA_AVAILABLE:
        st.info("üìä MCA aplicado a variables categ√≥ricas")
        
        try:
            # Pipeline para imputaci√≥n y OneHotEncoding de categ√≥ricas (como en el notebook)
            cat_pipeline_mca = Pipeline([
                ('imputer', SimpleImputer(strategy='most_frequent')),
                ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
            ])
            
            # Aplicar preprocesamiento categ√≥rico en train y test
            X_train_cat_processed = cat_pipeline_mca.fit_transform(X_train[categorical_cols])
            X_test_cat_processed = cat_pipeline_mca.transform(X_test[categorical_cols])
            
            # Convertir a DataFrame para que mca.MCA funcione (necesita nombres de columnas)
            cat_feature_names_processed = cat_pipeline_mca.named_steps['encoder'].get_feature_names_out(categorical_cols)
            X_train_cat_processed_df = pd.DataFrame(X_train_cat_processed, columns=cat_feature_names_processed, index=X_train.index)
            X_test_cat_processed_df = pd.DataFrame(X_test_cat_processed, columns=cat_feature_names_processed, index=X_test.index)
            
            # Aplicar MCA SOLO a los datos categ√≥ricos de entrenamiento procesados (OneHotEncoded)
            mca_model = MCA(X_train_cat_processed_df, ncols=X_train_cat_processed_df.shape[1])
            
            # Obtener los componentes MCA para entrenamiento y prueba
            # fs_r_sup calcula los factores principales para las filas (observaciones)
            X_train_mca_categorical = mca_model.fs_r_sup(X_train_cat_processed_df)
            X_test_mca_categorical = mca_model.fs_r_sup(X_test_cat_processed_df)
            
            st.write(f"**Shape de X_train_mca_categorical:** {X_train_mca_categorical.shape}")
            st.write(f"**Shape de X_test_mca_categorical:** {X_test_mca_categorical.shape}")
            
            # Valores singulares y autovalores
            sv = mca_model.s
            eigvals = sv ** 2
            explained_var = eigvals / eigvals.sum()
            cum_explained_var = np.cumsum(explained_var)
            
            # N√∫mero de componentes para >=70% varianza explicada
            n_components_70 = np.argmax(cum_explained_var >= 0.7) + 1
            st.write(f"**Componentes MCA para >=70% varianza explicada:** {n_components_70}")
            
            # Graficar varianza acumulada
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.plot(range(1, len(cum_explained_var)+1), cum_explained_var, marker='o', linestyle='--')
            ax.axhline(y=0.7, color='r', linestyle='-', label='70% Varianza Acumulada')
            ax.axvline(x=n_components_70, color='g', linestyle='--', label=f'{n_components_70} Componentes (>=70%)')
            ax.set_xlabel('Dimensiones MCA')
            ax.set_ylabel('Varianza acumulada explicada')
            ax.set_title('Varianza acumulada explicada por MCA (Variables Categ√≥ricas, ajustado en entrenamiento)')
            ax.grid(True)
            ax.legend()
            st.pyplot(fig)
            
            # Scatter plot MCA1 vs MCA2
            if X_train_mca_categorical.shape[1] >= 2:
                fig, ax = plt.subplots(figsize=(10, 8))
                scatter = ax.scatter(X_train_mca_categorical[:,0], X_train_mca_categorical[:,1], 
                                   c=[0 if target == 'healthy' else 1 for target in y_train],
                                   cmap='viridis', alpha=0.7)
                ax.set_xlabel('Dimensi√≥n MCA 1')
                ax.set_ylabel('Dimensi√≥n MCA 2')
                ax.set_title('Scatterplot Dimensi√≥n MCA 1 vs Dimensi√≥n MCA 2 (Variables Categ√≥ricas)')
                plt.colorbar(scatter, label='Target (0=healthy, 1=diseased)')
                ax.grid(True)
                st.pyplot(fig)
            
            # Seleccionar solo los primeros n_components_70 de MCA
            X_train_mca_selected = X_train_mca_categorical[:, :n_components_70]
            X_test_mca_selected = X_test_mca_categorical[:, :n_components_70]
            
            # Concatenar los componentes de PCA y los componentes seleccionados de MCA
            X_train_combined = np.hstack((X_train_pca, X_train_mca_selected))
            X_test_combined = np.hstack((X_test_pca, X_test_mca_selected))
            
            st.write(f"**Shape de X_train_pca_mca:** {X_train_combined.shape}")
            st.write(f"**Shape de X_test_pca_mca:** {X_test_combined.shape}")
            
            n_mca_components = n_components_70
            
            st.success(f"‚úÖ MCA: {n_mca_components} componentes explican >=70% de la varianza")
            
        except Exception as e:
            st.error(f"Error en MCA: {str(e)}")
            st.warning("‚ö†Ô∏è Usando PCA como alternativa para variables categ√≥ricas")
            
            # Fallback a PCA
            cat_pipeline_alt = Pipeline([
                ('imputer', SimpleImputer(strategy='most_frequent')),
                ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
            ])
            
            X_train_cat = cat_pipeline_alt.fit_transform(X_train[categorical_cols])
            X_test_cat = cat_pipeline_alt.transform(X_test[categorical_cols])
            
            pca_cat = PCA(n_components=min(5, X_train_cat.shape[1]), random_state=123)
            X_train_mca_selected = pca_cat.fit_transform(X_train_cat)
            X_test_mca_selected = pca_cat.transform(X_test_cat)
            
            # Combinar PCA y MCA (fallback)
            X_train_combined = np.hstack([X_train_pca, X_train_mca_selected])
            X_test_combined = np.hstack([X_test_pca, X_test_mca_selected])
            n_mca_components = X_train_mca_selected.shape[1]
    
    else:
        st.warning("‚ö†Ô∏è Librer√≠a MCA no disponible, usando reducci√≥n dimensional alternativa")
        # Usar PCA en variables categ√≥ricas codificadas como alternativa
        cat_pipeline_alt = Pipeline([
            ('imputer', SimpleImputer(strategy='most_frequent')),
            ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
        ])
        
        X_train_cat = cat_pipeline_alt.fit_transform(X_train[categorical_cols])
        X_test_cat = cat_pipeline_alt.transform(X_test[categorical_cols])
        
        pca_cat = PCA(n_components=min(5, X_train_cat.shape[1]), random_state=123)
        X_train_mca_selected = pca_cat.fit_transform(X_train_cat)
        X_test_mca_selected = pca_cat.transform(X_test_cat)
        
        # Combinar PCA y MCA (alternativo)
        X_train_combined = np.hstack([X_train_pca, X_train_mca_selected])
        X_test_combined = np.hstack([X_test_pca, X_test_mca_selected])
        n_mca_components = X_train_mca_selected.shape[1]
    
    # Mostrar m√©tricas finales
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Componentes PCA", X_train_pca.shape[1])
    with col2:
        st.metric("Componentes MCA", n_mca_components)
    with col3:
        st.metric("Total combinado", X_train_combined.shape[1])
    
    return {
        'X_train_pca_mca': X_train_combined,
        'X_test_pca_mca': X_test_combined,
        'pca_components': X_train_pca.shape[1],
        'mca_components': n_mca_components,
        'mensaje': 'PCA y MCA aplicados correctamente'
    }

def aplicar_balanceo(estado):
    """Aplica t√©cnicas de balanceo de datos"""
    st.subheader("‚öñÔ∏è T√©cnicas de Balanceo")
    
    # Usar los datos de PCA+MCA combinados
    X_train_selected = estado['X_train_selected']
    y_train_enc = estado['y_train_enc']
    
    st.write("### Distribuci√≥n Original vs Balanceada")
    
    # Mostrar distribuci√≥n original
    col1, col2 = st.columns(2)
    
    with col1:
        original_counts = pd.Series(y_train_enc).value_counts()
        st.write("**Distribuci√≥n Original:**")
        fig, ax = plt.subplots(figsize=(6, 4))
        bars = ax.bar(['Healthy (0)', 'Diseased (1)'], original_counts.values, color=['lightblue', 'lightcoral'])
        ax.set_title('Distribuci√≥n Original')
        ax.set_ylabel('N√∫mero de Muestras')
        
        # Agregar n√∫meros sobre las barras
        for bar, count in zip(bars, original_counts.values):
            height = bar.get_height()
            ax.annotate(f'{count:,}', (bar.get_x() + bar.get_width()/2, height),
                       ha='center', va='bottom', fontsize=10)
        
        st.pyplot(fig)
    
    # Aplicar SMOTETomek como t√©cnica de balanceo
    balanceador = SMOTETomek(random_state=123)
    X_train_balanced, y_train_balanced = balanceador.fit_resample(X_train_selected, y_train_enc)
    
    with col2:
        balanced_counts = pd.Series(y_train_balanced).value_counts()
        st.write("**Distribuci√≥n Balanceada (SMOTETomek):**")
        fig, ax = plt.subplots(figsize=(6, 4))
        bars = ax.bar(['Healthy (0)', 'Diseased (1)'], balanced_counts.values, color=['lightgreen', 'orange'])
        ax.set_title('Distribuci√≥n Balanceada')
        ax.set_ylabel('N√∫mero de Muestras')
        
        # Agregar n√∫meros sobre las barras
        for bar, count in zip(bars, balanced_counts.values):
            height = bar.get_height()
            ax.annotate(f'{count:,}', (bar.get_x() + bar.get_width()/2, height),
                       ha='center', va='bottom', fontsize=10)
        
        st.pyplot(fig)
    
    # Mostrar m√©tricas de balanceo
    col1, col2, col3 = st.columns(3)
    with col1:
        st.metric("Muestras originales", f"{len(y_train_enc):,}")
    with col2:
        st.metric("Muestras balanceadas", f"{len(y_train_balanced):,}")
    with col3:
        ratio_original = original_counts.min() / original_counts.max()
        ratio_balanced = balanced_counts.min() / balanced_counts.max()
        st.metric("Ratio balanceado", f"{ratio_balanced:.2f}", f"+{ratio_balanced - ratio_original:.2f}")
    
    st.success("‚úÖ Balanceo aplicado con SMOTETomek")
    
    return {
        'X_train_balanced': X_train_balanced,
        'y_train_balanced': y_train_balanced,
        'balanceador_usado': 'SMOTETomek',
        'mensaje': 'Datos balanceados correctamente'
    }

def entrenar_modelos(estado):
    """Entrena m√∫ltiples modelos de clasificaci√≥n"""
    st.subheader("ü§ñ Modelos de Clasificaci√≥n")
    
    X_train_balanced = estado['X_train_balanced']
    y_train_balanced = estado['y_train_balanced']
    X_test_selected = estado['X_test_selected']  # Usar datos de rf para test
    y_test_enc = estado['y_test_enc']
    le = estado['le']
    
    # Definir modelos
    modelos = {
        "Random Forest": RandomForestClassifier(n_estimators=100, random_state=123, class_weight='balanced'),
        "Gradient Boosting": HistGradientBoostingClassifier(random_state=123, class_weight='balanced'),
        "Logistic Regression": LogisticRegression(random_state=123, class_weight='balanced', max_iter=1000),
        "KNN": KNeighborsClassifier(n_neighbors=5),
        "Extra Trees": ExtraTreesClassifier(n_estimators=100, random_state=123, class_weight='balanced')
    }
    
    resultados = {}
    roc_data = {}
    
    st.write("### Entrenamiento y Evaluaci√≥n de Modelos")
    
    progress_bar_modelos = st.progress(0)
    status_modelos = st.empty()
    
    for i, (nombre, modelo) in enumerate(modelos.items()):
        status_modelos.text(f"Entrenando {nombre}...")
        progress_bar_modelos.progress((i + 1) / len(modelos))
        
        try:
            # Entrenar modelo
            modelo.fit(X_train_balanced, y_train_balanced)
            
            # Predicciones
            if hasattr(modelo, "predict_proba"):
                y_proba = modelo.predict_proba(X_test_selected)[:, 1]
            elif hasattr(modelo, "decision_function"):
                y_proba = modelo.decision_function(X_test_selected)
                # Normalizar scores para que est√©n entre 0 y 1
                y_proba = (y_proba - y_proba.min()) / (y_proba.max() - y_proba.min())
            else:
                # Si no tiene probabilidades, usar predicciones binarias
                y_proba = modelo.predict(X_test_selected)
            
            # Buscar mejor umbral para F1-score
            best_f1 = 0
            best_threshold = 0.5
            
            for threshold in np.arange(0.1, 0.91, 0.05):
                y_pred_threshold = (y_proba >= threshold).astype(int)
                f1_macro = f1_score(y_test_enc, y_pred_threshold, average='macro')
                if f1_macro > best_f1:
                    best_f1 = f1_macro
                    best_threshold = threshold
            
            # Predicciones finales con mejor umbral
            y_pred = (y_proba >= best_threshold).astype(int)
            
            # Calcular m√©tricas
            accuracy = accuracy_score(y_test_enc, y_pred)
            precision = precision_score(y_test_enc, y_pred, average='macro')
            recall = recall_score(y_test_enc, y_pred, average='macro')
            f1_macro = f1_score(y_test_enc, y_pred, average='macro')
            
            # ROC AUC
            try:
                roc_auc = roc_auc_score(y_test_enc, y_proba)
                fpr, tpr, _ = roc_curve(y_test_enc, y_proba)
                roc_data[nombre] = {'fpr': fpr, 'tpr': tpr, 'auc': roc_auc}
            except:
                roc_auc = 0.5
            
            # Guardar resultados
            resultados[nombre] = {
                'accuracy': accuracy,
                'precision': precision,
                'recall': recall,
                'f1_macro': f1_macro,
                'roc_auc': roc_auc,
                'best_threshold': best_threshold,
                'y_pred': y_pred,
                'y_proba': y_proba
            }
            
        except Exception as e:
            st.error(f"Error entrenando {nombre}: {str(e)}")
            resultados[nombre] = {
                'accuracy': 0, 'precision': 0, 'recall': 0, 
                'f1_macro': 0, 'roc_auc': 0.5, 'best_threshold': 0.5,
                'error': str(e)
            }
    
    status_modelos.text("‚úÖ Entrenamiento completado")
    
    return {
        'resultados_modelos': resultados,
        'roc_data': roc_data,
        'mejor_modelo': max(resultados.keys(), key=lambda k: resultados[k]['f1_macro']),
        'mensaje': 'Modelos entrenados correctamente'
    }

def generar_resultados(estado):
    """Genera y muestra los resultados finales"""
    st.subheader("Resultados Finales")
    
    resultados = estado['resultados_modelos']
    roc_data = estado['roc_data']
    mejor_modelo = estado['mejor_modelo']
    le = estado['le']
    y_test_enc = estado['y_test_enc']
    
    # Tabla comparativa de resultados
    st.write("### Comparaci√≥n de Modelos")
    
    df_resultados = pd.DataFrame(resultados).T
    df_resultados = df_resultados[['accuracy', 'precision', 'recall', 'f1_macro', 'roc_auc']]
    df_resultados = df_resultados.round(3)
    
    # Destacar el mejor modelo
    st.dataframe(
        df_resultados.style.highlight_max(axis=0, color='lightgreen'),
        use_container_width=True
    )
    
    # M√©tricas del mejor modelo
    st.write(f"### üèÜ Mejor Modelo: {mejor_modelo}")
    
    col1, col2, col3, col4, col5 = st.columns(5)
    
    best_results = resultados[mejor_modelo]
    with col1:
        st.metric("Accuracy", f"{best_results['accuracy']:.3f}")
    with col2:
        st.metric("Precision", f"{best_results['precision']:.3f}")
    with col3:
        st.metric("Recall", f"{best_results['recall']:.3f}")
    with col4:
        st.metric("F1-Score", f"{best_results['f1_macro']:.3f}")
    with col5:
        st.metric("ROC AUC", f"{best_results['roc_auc']:.3f}")
    
    # Curvas ROC
    if roc_data:
        st.write("### Curvas ROC - Comparaci√≥n de Modelos")
        
        fig, ax = plt.subplots(figsize=(10, 8))
        
        for nombre, data in roc_data.items():
            ax.plot(data['fpr'], data['tpr'], lw=2, 
                   label=f'{nombre} (AUC = {data["auc"]:.3f})')
        
        ax.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', 
               label='Clasificador Aleatorio (AUC = 0.500)')
        
        ax.set_xlim([0.0, 1.0])
        ax.set_ylim([0.0, 1.05])
        ax.set_xlabel('Tasa de Falsos Positivos (FPR)')
        ax.set_ylabel('Tasa de Verdaderos Positivos (TPR)')
        ax.set_title('Curvas ROC - Comparaci√≥n de Modelos', fontweight='bold')
        ax.legend(loc="lower right")
        ax.grid(True, alpha=0.3)
        
        st.pyplot(fig)
    
    # Matriz de confusi√≥n del mejor modelo
    if 'y_pred' in best_results:
        st.write("### Matriz de Confusi√≥n - Mejor Modelo")
        
        cm = confusion_matrix(y_test_enc, best_results['y_pred'])
        
        fig, ax = plt.subplots(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                   xticklabels=le.classes_, yticklabels=le.classes_, ax=ax)
        ax.set_title(f'Matriz de Confusi√≥n - {mejor_modelo}', fontweight='bold')
        ax.set_xlabel('Predicci√≥n')
        ax.set_ylabel('Valor Real')
        
        st.pyplot(fig)
    
    return {
        'resultados_finales': {
            'mejor_modelo': mejor_modelo,
            'metricas': best_results,
            'comparacion': df_resultados,
            'interpretacion': 'An√°lisis completado'
        }
    }

# Funciones de visualizaci√≥n individual (para el men√∫ lateral)
def mostrar_analisis_exploratorio():
    st.header("An√°lisis Exploratorio de Datos")
    st.info("üí° Utiliza el bot√≥n 'üîÑ Ejecutar An√°lisis Completo' para ver el an√°lisis exploratorio completo con datos reales.")
    
    st.markdown("""
    ### Objetivos del An√°lisis Exploratorio:
    - **Comprensi√≥n de la estructura** de los datos de salud
    - **Identificaci√≥n de patrones** en variables de estilo de vida  
    - **Detecci√≥n de valores at√≠picos** y datos faltantes
    - **An√°lisis de correlaciones** entre variables predictoras
    - **Evaluaci√≥n del desbalance** en la variable objetivo
    
    ### Variables Analizadas:
    #### Variables Num√©ricas:
    - age, bmi_corrected, blood_pressure, cholesterol, glucose, sleep_hours, weight, height
    
    #### Variables Categ√≥ricas:
    - gender, marital_status, sleep_quality, smoking_level, diet_type, healthcare_access, occupation
    """)

def mostrar_preprocesamiento():
    st.header("Preprocesamiento de Datos")
    st.info("üí° Utiliza el bot√≥n 'üîÑ Ejecutar An√°lisis Completo' para ver el preprocesamiento completo.")
    
    st.markdown("""
    ### T√©cnicas de Preprocesamiento Implementadas:
    
    #### 1. Divisi√≥n de Datos:
    - **Divisi√≥n estratificada** 70/30 (entrenamiento/prueba)
    - **Preservaci√≥n de proporciones** de clases
    - **Reproducibilidad** con semilla aleatoria fija
    
    #### 2. Pipelines de Transformaci√≥n:
    - **Variables Num√©ricas**: Imputaci√≥n (media) + StandardScaler
    - **Variables Categ√≥ricas**: Imputaci√≥n (moda) + OneHotEncoder
    - **Prevenci√≥n de data leakage** con fit/transform separation
    
    #### 3. Codificaci√≥n de Variable Objetivo:
    - **LabelEncoder** para convertir 'healthy'/'diseased' a 0/1
    - **Mantenimiento de interpretabilidad** cl√≠nica
    """)

def mostrar_seleccion_caracteristicas():
    st.header("Selecci√≥n de Caracter√≠sticas")
    st.info("üí° Utiliza el bot√≥n 'üîÑ Ejecutar An√°lisis Completo' para ver la selecci√≥n de caracter√≠sticas completa.")
    
    st.markdown("""
    ### M√©todos de Selecci√≥n Comparados:
    
    #### 1. SelectKBest (Chi-cuadrado):
    - **Dependencia estad√≠stica** entre variables categ√≥ricas y target
    - **Discretizaci√≥n** de variables num√©ricas requerida
    - **Ventaja**: R√°pido y estad√≠sticamente fundamentado
    - **Limitaci√≥n**: Solo detecta relaciones lineales
    
    #### 2. SelectKBest (Informaci√≥n Mutua):
    - **Relaciones no lineales** entre variables y target
    - **Teor√≠a de la informaci√≥n** (reducci√≥n de entrop√≠a)
    - **Ventaja**: Captura dependencias complejas
    - **Limitaci√≥n**: Estimaci√≥n puede ser ruidosa
    
    #### 3. Random Forest (M√©todo Incrustado):
    - **Importancia basada en impureza** en √°rboles de decisi√≥n
    - **Considera interacciones** entre variables naturalmente
    - **Ventaja**: Interpretabilidad cl√≠nica directa
    - **Aplicaci√≥n**: Ideal para bioestad√≠stica
    
    #### 4. RFECV (M√©todo de Envoltura):
    - **Eliminaci√≥n recursiva** con validaci√≥n cruzada
    - **Optimizaci√≥n espec√≠fica** para algoritmo de clasificaci√≥n
    - **Ventaja**: Maximiza rendimiento predictivo
    - **Limitaci√≥n**: Computacionalmente costoso
    
    ### Criterio de Selecci√≥n:
    **90% de importancia acumulada** como umbral para balancear informaci√≥n vs reducci√≥n dimensional.
    """)

def mostrar_pca_mca():
    st.header("PCA y MCA")
    st.info("üí° Utiliza el bot√≥n 'üîÑ Ejecutar An√°lisis Completo' para ver PCA y MCA completos.")
    
    st.markdown("""
    ### An√°lisis de Componentes Principales (PCA):
    
    #### Fundamento Te√≥rico:
    - **Reducci√≥n de dimensionalidad lineal** preservando m√°xima varianza
    - **Eliminaci√≥n de redundancia** entre variables correlacionadas
    - **Componentes ortogonales** que capturan patrones principales
    
    #### Aplicaci√≥n en Variables Num√©ricas:
    - age, bmi_corrected, blood_pressure, cholesterol, glucose, etc.
    - **Criterio**: 70% de varianza explicada acumulada
    - **Interpretaci√≥n**: Componentes como "factores de salud general"
    
    ### An√°lisis de Correspondencias M√∫ltiples (MCA):
    
    #### Fundamento Te√≥rico:
    - **Extensi√≥n de PCA** para variables categ√≥ricas/nominales
    - **An√°lisis de asociaciones** entre categor√≠as
    - **Visualizaci√≥n de perfiles** de comportamiento
    
    #### Aplicaci√≥n en Variables Categ√≥ricas:
    - gender, marital_status, diet_type, healthcare_access, etc.
    - **Objetivo**: Identificar patrones de estilo de vida
    - **Ventaja**: Mantiene naturaleza categ√≥rica de los datos
    
    ### Combinaci√≥n PCA + MCA:
    - **Enfoque h√≠brido** para datos mixtos (num√©ricos + categ√≥ricos)
    - **Representaci√≥n compacta** del espacio de caracter√≠sticas completo
    - **Preservaci√≥n de informaci√≥n** tanto cuantitativa como cualitativa
    """)

def mostrar_balanceo():
    st.header("T√©cnicas de Balanceo")
    st.info("üí° Utiliza el bot√≥n 'üîÑ Ejecutar An√°lisis Completo' para ver las t√©cnicas de balanceo completas.")
    
    st.markdown("""
    ### Problem√°tica del Desbalance de Clases:
    
    #### Desaf√≠os Identificados:
    - **Distribuci√≥n**: ~70% healthy vs ~30% diseased
    - **Sesgo predictivo** hacia clase mayoritaria
    - **Baja sensibilidad** para detectar casos de riesgo
    - **M√©tricas enga√±osas** (alta accuracy, baja utilidad cl√≠nica)
    
    ### T√©cnicas de Balanceo Evaluadas:
    
    #### 1. SMOTE (Synthetic Minority Oversampling):
    - **Generaci√≥n sint√©tica** de ejemplos minoritarios
    - **Interpolaci√≥n k-NN** en espacio de caracter√≠sticas
    - **Ventaja**: Evita overfitting por duplicaci√≥n
    - **Aplicaci√≥n cl√≠nica**: Aumenta detecci√≥n de casos de riesgo
    
    #### 2. SMOTETomek (T√©cnica H√≠brida):
    - **Combinaci√≥n**: SMOTE + limpieza Tomek Links
    - **Oversampling inteligente** + eliminaci√≥n de outliers
    - **Ventaja**: Mejora frontera de decisi√≥n
    - **Resultado**: Datos m√°s limpios y balanceados
    
    #### 3. BorderlineSMOTE:
    - **SMOTE selectivo** en ejemplos frontera
    - **Enfoque**: Casos dif√≠ciles de clasificar
    - **Ventaja**: Mejora separabilidad de clases
    
    ### Evaluaci√≥n de T√©cnicas:
    - **M√©tricas balanceadas**: F1-macro, Recall, Precision
    - **ROC AUC** para evaluar capacidad discriminativa
    - **Validaci√≥n cruzada estratificada**
    - **Impacto en interpretabilidad cl√≠nica**
    """)

def mostrar_modelos():
    st.header("Modelos de Clasificaci√≥n")
    st.info("üí° Utiliza el bot√≥n 'üîÑ Ejecutar An√°lisis Completo' para ver el entrenamiento de modelos completo.")
    
    st.markdown("""
    ### Algoritmos de Clasificaci√≥n Implementados:
    
    #### 1. Random Forest:
    - **Ensemble de √°rboles** con bagging
    - **Ventajas**: Maneja no-linealidad, importancia de variables, robusto
    - **Aplicaci√≥n cl√≠nica**: Sistemas de apoyo diagn√≥stico interpretables
    - **Hiperpar√°metros**: n_estimators, max_depth, min_samples_split
    
    #### 2. Gradient Boosting (HistGradientBoosting):
    - **Ensemble secuencial** que corrige errores previos
    - **Ventajas**: Excelente capacidad predictiva, maneja patrones complejos
    - **Aplicaci√≥n cl√≠nica**: Modelos de pron√≥stico y estratificaci√≥n de riesgo
    - **Optimizaci√≥n**: learning_rate, max_iter, max_depth
    
    #### 3. Regresi√≥n Log√≠stica:
    - **Modelo lineal** con interpretaci√≥n probabil√≠stica
    - **Ventajas**: Interpretabilidad directa, coeficientes = odds ratios
    - **Aplicaci√≥n cl√≠nica**: Scores de riesgo cardiovascular, modelos explicativos
    - **Regularizaci√≥n**: L1, L2, ElasticNet para selecci√≥n autom√°tica
    
    #### 4. K-Nearest Neighbors (KNN):
    - **Clasificaci√≥n por similaridad** local
    - **Ventajas**: No param√©trico, adapta a estructura local
    - **Aplicaci√≥n cl√≠nica**: Diagn√≥stico por casos similares, medicina personalizada
    - **Par√°metros**: n_neighbors, weights, metric
    
    #### 5. Extra Trees:
    - **Ensemble con aleatoriedad** en divisi√≥n de nodos
    - **Ventajas**: Reduce overfitting, r√°pido entrenamiento
    - **Aplicaci√≥n cl√≠nica**: Modelos robustos con datos ruidosos
    
    ### Optimizaci√≥n de Hiperpar√°metros:
    - **RandomizedSearchCV** para exploraci√≥n eficiente
    - **Validaci√≥n cruzada estratificada** (5 folds)
    - **M√©trica objetivo**: F1-macro score
    - **B√∫squeda de umbral √≥ptimo** para maximizar F1-score
    
    ### Evaluaci√≥n Integral:
    - **M√©tricas m√∫ltiples**: Accuracy, Precision, Recall, F1-macro, ROC AUC
    - **Curvas ROC** para comparaci√≥n visual
    - **Matrices de confusi√≥n** para an√°lisis detallado
    - **Interpretabilidad cl√≠nica** de resultados
    """)

def mostrar_resultados():
    st.header("Resultados y Evaluaci√≥n")
    st.info("üí° Utiliza el bot√≥n 'üîÑ Ejecutar An√°lisis Completo' para ver los resultados completos.")
    
    st.markdown("""
    ### M√©tricas de Evaluaci√≥n Utilizadas:
    
    #### Para Clasificaci√≥n Binaria Desbalanceada:
    - **Accuracy**: Proporci√≥n total de predicciones correctas
    - **Precision**: Proporci√≥n de predicciones positivas correctas
    - **Recall (Sensitivity)**: Proporci√≥n de casos positivos detectados
    - **F1-Score**: Media arm√≥nica entre Precision y Recall
    - **ROC AUC**: √Årea bajo la curva ROC (capacidad discriminativa)
    
    ### Interpretaci√≥n Cl√≠nica:
    
    #### Contexto de Aplicaci√≥n en Salud:
    - **Falsos Negativos** (alta gravedad): Pacientes enfermos clasificados como sanos
    - **Falsos Positivos** (menor gravedad): Pacientes sanos clasificados como enfermos
    - **Recall alto** es prioritario para detecci√≥n de casos de riesgo
    - **Precision adecuada** para evitar alarmas innecesarias
    
    ### An√°lisis Comparativo:
    - **Tablas de rendimiento** por algoritmo y t√©cnica de balanceo
    - **Curvas ROC superpuestas** para comparaci√≥n visual
    - **Matrices de confusi√≥n** para an√°lisis de errores
    - **Identificaci√≥n del modelo √≥ptimo** basado en F1-macro score
    
    ### Limitaciones Identificadas:
    - **Rendimiento cercano al aleatorio** (AUC ‚âà 0.5)
    - **Dificultad para discriminar** entre clases healthy/diseased
    - **Posible insuficiencia** de variables predictivas en el dataset
    - **Necesidad de ingenier√≠a** de caracter√≠sticas adicional
    """)

def mostrar_conclusiones():
    st.header("Conclusiones")
    
    st.markdown("""
    ## Conclusiones del An√°lisis Comparativo
    
    ### T√©cnicas de Selecci√≥n de Caracter√≠sticas
    
    Se implementaron **cuatro m√©todos de selecci√≥n** de caracter√≠sticas (Chi-cuadrado, Informaci√≥n Mutua, 
    Random Forest y RFECV), los cuales mostraron convergencia parcial en la identificaci√≥n de variables 
    relevantes. Si bien se logr√≥ definir un conjunto "core" de predictores, **ning√∫n m√©todo permiti√≥ 
    construir modelos con capacidad discriminativa significativa**. Esto sugiere que, aunque las variables 
    seleccionadas son las m√°s informativas dentro del dataset disponible, su poder explicativo para 
    diferenciar entre personas sanas y enfermas es limitado.
    
    ### Reducci√≥n de Dimensionalidad
    
    **PCA** permiti√≥ reducir la dimensionalidad de las variables num√©ricas, preservando el 70% de la 
    varianza con pocos componentes principales. **MCA** complement√≥ el an√°lisis en variables categ√≥ricas, 
    proporcionando una representaci√≥n m√°s compacta de los datos. Sin embargo, al tener resultados muy 
    similares a las t√©cnicas de selecci√≥n de caracter√≠sticas, no se utilizaron en el modelo final.
    
    ### T√©cnicas de Balanceo
    
    La evaluaci√≥n de m√∫ltiples t√©cnicas de balanceo mostr√≥ que **SMOTETomek** ofreci√≥ el mejor equilibrio 
    entre generaci√≥n de muestras sint√©ticas y limpieza de fronteras de decisi√≥n. El balanceo permiti√≥ 
    mejorar la proporci√≥n de clases en el conjunto de entrenamiento, pero **no fue suficiente para que 
    los modelos detectaran eficazmente la clase minoritaria**. La precisi√≥n y el recall para la clase 
    "enfermo" se mantuvieron bajos en todos los algoritmos, reflejando la dificultad del problema.
    
    ### Rendimiento de Algoritmos
    
    El an√°lisis comparativo de **cinco algoritmos de clasificaci√≥n** revel√≥ que **ninguno logr√≥ un 
    desempe√±o significativamente superior al azar**:
    
    - **Random Forest**: Ligera ventaja sobre otros modelos, pero sin capacidad real de discriminaci√≥n
    - **HistGradientBoosting**: M√©tricas similares a Random Forest
    - **KNN**: Los m√©todos basados en vecinos tampoco lograron captar patrones diferenciadores
    - **ExtraTrees**: √önico modelo con AUC ligeramente superior, pero a√∫n dentro del rango aleatorio
    - **Regresi√≥n Log√≠stica**: La interpretabilidad no se tradujo en mejor rendimiento
    
    En todos los casos, la **accuracy se mantuvo entre 0.56 y 0.59**, y el F1-macro cerca de 0.5, 
    indicando que los modelos tienden a predecir la clase mayoritaria ("healthy") con baja sensibilidad 
    para la clase minoritaria ("diseased").
    
    ### M√©tricas de Evaluaci√≥n
    
    Las m√©tricas obtenidas (precision, recall, F1-score, AUC) muestran que **la capacidad de los modelos 
    para distinguir entre clases es pr√°cticamente nula**. El AUC cercano a 0.5 en todos los algoritmos 
    confirma que el desempe√±o es equivalente al azar. La matriz de confusi√≥n revela que la mayor√≠a de 
    los casos "diseased" no son detectados correctamente, limitando la utilidad cl√≠nica de los modelos.
    
    ---
    
    ## Conclusi√≥n Final
    
    A pesar de aplicar **t√©cnicas avanzadas de selecci√≥n de caracter√≠sticas**, **reducci√≥n de 
    dimensionalidad** y **balanceo de clases**, **los modelos no logran superar el desempe√±o aleatorio**. 
    
    ### Posibles Causas:
    - **Falta de variables verdaderamente discriminantes** en el dataset
    - **Presencia de ruido** o informaci√≥n irrelevante
    - **Complejidad inherente** del problema de predicci√≥n de salud
    - **Limitaciones del dataset sint√©tico** utilizado para la demostraci√≥n
    
    ### Recomendaciones:
    - **Explorar nuevas fuentes de datos** con variables m√°s espec√≠ficas
    - **Realizar ingenier√≠a de caracter√≠sticas** m√°s profunda
    - **Considerar enfoques alternativos** como deep learning o m√©todos ensemble avanzados
    - **Incorporar conocimiento experto** del dominio m√©dico
    - **Validar con datasets reales** de mayor calidad
    
    ### Valor del An√°lisis:
    Este trabajo demuestra la **importancia de una metodolog√≠a rigurosa** en machine learning aplicado 
    a la salud, evidenciando que no siempre es posible obtener modelos predictivos √∫tiles, incluso 
    aplicando las mejores pr√°cticas t√©cnicas. La **transparencia en los resultados negativos** es 
    fundamental para el avance cient√≠fico en bioestad√≠stica.
    """)

def mostrar_resultados_completos(resultados_finales):
    """Muestra un resumen ejecutivo de todos los resultados"""
    st.header("Resumen Ejecutivo de Resultados")
    
    mejor_modelo = resultados_finales['mejor_modelo']
    metricas = resultados_finales['metricas']
    
    st.success(f"**Mejor Modelo Identificado:** {mejor_modelo}")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric("F1-Score", f"{metricas['f1_macro']:.3f}")
        st.metric("ROC AUC", f"{metricas['roc_auc']:.3f}")

    with col2:
        st.metric("Accuracy", f"{metricas['accuracy']:.3f}")
        st.metric("Precision", f"{metricas['precision']:.3f}")
    
    with col3:
        st.metric("Recall", f"{metricas['recall']:.3f}")
        st.metric("Threshold", f"{metricas['best_threshold']:.2f}")

    # Interpretaci√≥n autom√°tica
    if metricas['roc_auc'] > 0.7:
        interpretacion = "üü¢ **Excelente capacidad predictiva**"
    elif metricas['roc_auc'] > 0.6:
        interpretacion = "üü° **Capacidad predictiva moderada**"
    else:
        interpretacion = "üî¥ **Capacidad predictiva limitada (‚âà aleatorio)**"
    
    st.markdown(f"### Interpretaci√≥n: {interpretacion}")
    
    if metricas['roc_auc'] <= 0.6:
        st.warning("""
        ‚ö†Ô∏è Los modelos muestran capacidad discriminativa limitada.
        Se recomienda:
        - Revisar la calidad y relevancia de las variables y los datos
        - Considerar fuentes de datos adicionales
        - Evaluar la necesidad de m√°s muestras o probar con otros modelos o t√©cnicas
        """)

def mostrar_seccion_resultados(seccion, resultados):
    """Muestra una secci√≥n espec√≠fica de los resultados del an√°lisis"""
    
    if seccion == "Resumen Completo":
        st.header("Resumen Completo del An√°lisis")
        
        if 'resultados_finales' in resultados:
            mostrar_resultados_completos(resultados['resultados_finales'])
        
        # Mostrar m√©tricas clave de cada paso
        st.subheader("üîç M√©tricas por Etapa")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown("**Datos**")
            if 'df' in resultados:
                st.metric("Registros totales", f"{len(resultados['df']):,}")
                st.metric("Variables num√©ricas", len(resultados.get('numerical_cols', [])))
                st.metric("Variables categ√≥ricas", len(resultados.get('categorical_cols', [])))
        
        with col2:
            st.markdown("**Reducci√≥n Dimensional**")
            if 'pca_components' in resultados:
                st.metric("Componentes PCA", resultados['pca_components'])
            if 'mca_components' in resultados:
                st.metric("Componentes MCA", resultados['mca_components'])
            if 'n_features_selected' in resultados:
                st.metric("Caracter√≠sticas seleccionadas", resultados['n_features_selected'])
        
        with col3:
            st.markdown("**Mejor Modelo**")
            if 'resultados_finales' in resultados:
                mejor_modelo = resultados['resultados_finales']['mejor_modelo']
                metricas = resultados['resultados_finales']['metricas']
                st.metric("Algoritmo", mejor_modelo)
                st.metric("F1-Score", f"{metricas.get('f1_macro', 0):.3f}")
                st.metric("ROC AUC", f"{metricas.get('roc_auc', 0):.3f}")
    
    elif seccion == "Carga de Datos":
        st.header("Carga de Datos")
        if 'df' in resultados:
            df = resultados['df']
            st.write("### Vista previa del dataset")
            st.dataframe(df.head())
            
            st.write("### Informaci√≥n del dataset")
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Total registros", f"{len(df):,}")
            with col2:
                st.metric("Variables num√©ricas", len(resultados.get('numerical_cols', [])))
            with col3:
                st.metric("Variables categ√≥ricas", len(resultados.get('categorical_cols', [])))
    
    elif seccion == "An√°lisis Exploratorio":
        st.header("An√°lisis Exploratorio")
        if 'df' in resultados:
            df = resultados['df']
            
            # Distribuci√≥n de la variable objetivo
            st.write("### Distribuci√≥n de la Variable Objetivo")
            target_counts = df['target'].value_counts()
            
            fig, ax = plt.subplots(figsize=(8, 5))
            bars = ax.bar(target_counts.index, target_counts.values, color=['#1f77b4', '#ff7f0e'])
            ax.set_title('Distribuci√≥n de la Variable Objetivo')
            ax.set_xlabel('Estado de Salud')
            ax.set_ylabel('N√∫mero de Personas')
            
            for bar, count in zip(bars, target_counts.values):
                height = bar.get_height()
                ax.annotate(f'{count:,}', (bar.get_x() + bar.get_width()/2, height),
                           ha='center', va='bottom')
            
            st.pyplot(fig)

    elif seccion == "PCA y MCA":
        st.header("Resultados PCA y MCA")

        col1, col2 = st.columns(2)
        with col1:
            if 'pca_components' in resultados:
                st.metric("Componentes PCA", resultados['pca_components'])
        with col2:
            if 'mca_components' in resultados:
                st.metric("Componentes MCA", resultados['mca_components'])
        
        st.info("üí° Los detalles completos de PCA y MCA se muestran durante la ejecuci√≥n del an√°lisis.")

    elif seccion == "Mejores Resultados":
        st.header("Mejores Resultados")

        if 'resultados_finales' in resultados:
            resultados_finales = resultados['resultados_finales']
            mejor_modelo = resultados_finales['mejor_modelo']
            metricas = resultados_finales['metricas']
            
            st.success(f"üèÜ **Mejor Modelo:** {mejor_modelo}")
            
            # Mostrar m√©tricas en columnas
            col1, col2, col3, col4, col5 = st.columns(5)
            
            with col1:
                st.metric("F1-Score", f"{metricas.get('f1_macro', 0):.3f}")
            with col2:
                st.metric("ROC AUC", f"{metricas.get('roc_auc', 0):.3f}")
            with col3:
                st.metric("Accuracy", f"{metricas.get('accuracy', 0):.3f}")
            with col4:
                st.metric("Precision", f"{metricas.get('precision', 0):.3f}")
            with col5:
                st.metric("Recall", f"{metricas.get('recall', 0):.3f}")
            
            # Interpretaci√≥n
            if metricas.get('roc_auc', 0) > 0.7:
                st.success("üü¢ **Excelente capacidad predictiva**")
            elif metricas.get('roc_auc', 0) > 0.6:
                st.warning("üü° **Capacidad predictiva moderada**")
            else:
                st.error("üî¥ **Capacidad predictiva limitada (‚âà aleatorio)**")
    
    elif seccion == "Comparaci√≥n de Modelos":
        st.header("Comparaci√≥n de Modelos")

        if 'resultados_modelos' in resultados:
            resultados_modelos = resultados['resultados_modelos']
            
            # Crear tabla comparativa
            df_comparacion = pd.DataFrame(resultados_modelos).T
            df_comparacion = df_comparacion[['accuracy', 'precision', 'recall', 'f1_macro', 'roc_auc']]
            df_comparacion = df_comparacion.round(3)
            
            st.write("### Tabla Comparativa de Modelos")
            st.dataframe(df_comparacion.style.highlight_max(axis=0, color='lightgreen'))
            
            st.info("Los valores destacados en verde representan las mejores m√©tricas por columna.")
    
    elif seccion == "Conclusiones Finales":
        st.header("Conclusiones Finales")
        mostrar_conclusiones()
    
    else:
        st.info(f"Secci√≥n '{seccion}' en desarrollo. Selecciona otra secci√≥n para ver los resultados.")

if __name__ == "__main__":
    main()